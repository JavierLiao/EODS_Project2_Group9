{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5293 - Proj2 - Group9\n",
    "## NLP with tweets related to COVID\n",
    "#### NLP pipeline with sentiment prediction\n",
    "* Tokenization\n",
    "    > Split text into tokens(sentences or words), for this question, we split the document into sentence for automatic summarization, and words for sentiment analysis and topic modeling\n",
    "* Screen out stop words and other meaningless corpus\n",
    "* Lemmatization\n",
    "    > Here we only use lemmatization rather than stemming is because lemmatization keeps the interpretability of words with their context. While stemming might lead to incorrect meaning. It is important to make morphological analysis of the words. \n",
    "* EDA: wordCloud with different sentiment\n",
    "    > Identify what poeple with different emotions were considering about\n",
    "* EDA: Word2vec with Clustering\n",
    "    > Word2Vec: Effective for detecting the synonymous words or suggesting additional words for a partial sentence\n",
    "\n",
    "    Clustering methods: K-means + DBScan\n",
    "\n",
    "    Use all the words in a specific part-of-speech from all the documents (e.g. all nouns / all adj.s)\n",
    "* (word2vec w/ recommendation)?\n",
    "* Topic Modeling: Feature extraction by TFIDF + Latent Dirichlet Allocation\n",
    "    Build a pipeline with KFoldCV to find the best topic number\n",
    "* Automatic summrization\n",
    "    > Identify what were most people thinking about or tweeting for\n",
    "* Sentiment Analysis: Classification for sentiment(5 classes: Neutral / Positive / Extremely Positive / Negative / Extremely Negative)\n",
    "    Potential Model: BERT?\n",
    "#### Preprocessing\n",
    "* One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kangshuoli/Documents/VScode_workspace/GR5293/EODS-Project2-Group9/EODS_Project2_Group9/doc'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_filtered</th>\n",
       "      <th>Word_list</th>\n",
       "      <th>Senten_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>['advice', 'talk', 'neighbour', 'family', 'exc...</td>\n",
       "      <td>['advice Talk to your neighbours family to exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>['coronavirus', 'australia', 'woolworth', 'giv...</td>\n",
       "      <td>['Coronavirus Australia: Woolworths to give el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>['food', 'stock', 'one', 'empty', 'please', 'd...</td>\n",
       "      <td>['My food stock is not the only one which is e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>['ready', 'go', 'supermarket', 'covid', 'outbr...</td>\n",
       "      <td>['Me, ready to go at supermarket during the #C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>['news', 'regionâ', '\\x92', 'first', 'confirme...</td>\n",
       "      <td>['As news of the regionÂ\\x92s first confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44250</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>['meanwhile', 'supermarket', 'israel', 'people...</td>\n",
       "      <td>['Meanwhile In A Supermarket in Israel -- Peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44251</th>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>['panic', 'buy', 'lot', 'nonperishable', 'item...</td>\n",
       "      <td>['Did you panic buy a lot of non-perishable it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44252</th>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Asst Prof of Economics was on talking about he...</td>\n",
       "      <td>['asst', 'prof', 'economics', 'talking', 'rece...</td>\n",
       "      <td>[\"Asst Prof of Economics @cconces was on @NBCP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44253</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>['gov', 'need', 'somethings', 'instead', 'biar...</td>\n",
       "      <td>[\"Gov need to do somethings instead of biar je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44254</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>I and members are committed to the safety of o...</td>\n",
       "      <td>['member', 'committed', 'safety', 'employee', ...</td>\n",
       "      <td>['I and @ForestandPaper members are committed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44255 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           OriginalTweet           Sentiment  \\\n",
       "0      advice Talk to your neighbours family to excha...            Positive   \n",
       "1      Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "2      My food stock is not the only one which is emp...            Positive   \n",
       "3      Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "4      As news of the regionÂs first confirmed COVID...            Positive   \n",
       "...                                                  ...                 ...   \n",
       "44250  Meanwhile In A Supermarket in Israel -- People...            Positive   \n",
       "44251  Did you panic buy a lot of non-perishable item...            Negative   \n",
       "44252  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral   \n",
       "44253  Gov need to do somethings instead of biar je r...  Extremely Negative   \n",
       "44254  I and @ForestandPaper members are committed to...  Extremely Positive   \n",
       "\n",
       "                                          Tweet_filtered  \\\n",
       "0      advice Talk to your neighbours family to excha...   \n",
       "1      Coronavirus Australia: Woolworths to give elde...   \n",
       "2      My food stock is not the only one which is emp...   \n",
       "3      Me, ready to go at supermarket during the #COV...   \n",
       "4      As news of the regionÂs first confirmed COVID...   \n",
       "...                                                  ...   \n",
       "44250  Meanwhile In A Supermarket in Israel -- People...   \n",
       "44251  Did you panic buy a lot of non-perishable item...   \n",
       "44252  Asst Prof of Economics was on talking about he...   \n",
       "44253  Gov need to do somethings instead of biar je r...   \n",
       "44254  I and members are committed to the safety of o...   \n",
       "\n",
       "                                               Word_list  \\\n",
       "0      ['advice', 'talk', 'neighbour', 'family', 'exc...   \n",
       "1      ['coronavirus', 'australia', 'woolworth', 'giv...   \n",
       "2      ['food', 'stock', 'one', 'empty', 'please', 'd...   \n",
       "3      ['ready', 'go', 'supermarket', 'covid', 'outbr...   \n",
       "4      ['news', 'regionâ', '\\x92', 'first', 'confirme...   \n",
       "...                                                  ...   \n",
       "44250  ['meanwhile', 'supermarket', 'israel', 'people...   \n",
       "44251  ['panic', 'buy', 'lot', 'nonperishable', 'item...   \n",
       "44252  ['asst', 'prof', 'economics', 'talking', 'rece...   \n",
       "44253  ['gov', 'need', 'somethings', 'instead', 'biar...   \n",
       "44254  ['member', 'committed', 'safety', 'employee', ...   \n",
       "\n",
       "                                             Senten_list  \n",
       "0      ['advice Talk to your neighbours family to exc...  \n",
       "1      ['Coronavirus Australia: Woolworths to give el...  \n",
       "2      ['My food stock is not the only one which is e...  \n",
       "3      ['Me, ready to go at supermarket during the #C...  \n",
       "4      ['As news of the regionÂ\\x92s first confirmed ...  \n",
       "...                                                  ...  \n",
       "44250  ['Meanwhile In A Supermarket in Israel -- Peop...  \n",
       "44251  ['Did you panic buy a lot of non-perishable it...  \n",
       "44252  [\"Asst Prof of Economics @cconces was on @NBCP...  \n",
       "44253  [\"Gov need to do somethings instead of biar je...  \n",
       "44254  ['I and @ForestandPaper members are committed ...  \n",
       "\n",
       "[44255 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Corona_NLP_filtered.csv\")\n",
    "df.drop(\n",
    "    \"Unnamed: 0\", \n",
    "    axis = 1,\n",
    "    inplace = True\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44255 entries, 0 to 44254\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   OriginalTweet   44255 non-null  object\n",
      " 1   Sentiment       44251 non-null  object\n",
      " 2   Tweet_filtered  44249 non-null  object\n",
      " 3   Word_list       44249 non-null  object\n",
      " 4   Senten_list     44249 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Done in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_remove.sub(r'', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "\n",
    "def lower(text):\n",
    "    low_text = text.lower()\n",
    "    return low_text\n",
    "\n",
    "def remove_num(text):\n",
    "    remove = re.sub(r'\\d+', '' ,text)\n",
    "    return remove\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    clean_list = [char for char in text if char not in string.punctuation]\n",
    "    clean_str = ''.join(clean_list)\n",
    "    return clean_str\n",
    "\n",
    "df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x: remove_urls(x)) \\\n",
    "                                               .apply(lambda x: remove_html(x)) \\\n",
    "                                               .apply(lambda x: lower(x)) \\\n",
    "                                               .apply(lambda x: remove_num(x)) \\\n",
    "                                               .apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "\n",
    "def classes_def(x):\n",
    "    if x ==  'Extremely Positive' or x == 'Positive':\n",
    "        return \"positive\"\n",
    "    elif x == \"Extremely Negative\" or x == 'Negative':\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "    \n",
    "train['Sentiment'] = train['Sentiment'].apply(lambda x: classes_def(x))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level Analysis\n",
    "1. wordCloud\n",
    "2. word2Vec w/ clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-level / Sentence-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27646e5cfdb25e10f4fd8ef0a3a49281af2a8af5fb226dbbb4749ab5404e27a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('eods-s22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
